GATK4 CNV Analysis Pipeline
A structured, reproducible workflow for preprocessing, CNV computation, and downstream statistical analysis using dbGaP RNA-seq data.

----------------------------------------------------------------------
Project Overview
----------------------------------------------------------------------
This repository provides an end-to-end workflow for performing copy number variation (CNV) analysis on large-scale cancer RNA-seq cohorts. The pipeline is organized into three stages:

1. Pre-processing — raw SRA handling, FASTQ generation, alignment, and file preparation (shell + Python + Jupyter).
2. Processing — GATK4 CNV workflow for read counting, PoN construction, denoising, and segmentation (shell).
3. Post-processing — gene-level CNV aggregation and statistical analyses (R), followed by survival analysis using Jupyter notebooks.

The workflow is designed for HPC execution on Slurm clusters and is compatible with dbGaP-restricted environments.

----------------------------------------------------------------------
Folder Structure
----------------------------------------------------------------------
workflow/
    01-pre_processing/
        01_pre.sh
        02_pre.sh
        03_pre.py
        04_pre.ipynb

    02-processing/
        01_main.sh
        02_main.sh
        03_main.sh
        04_main.sh
        05_main.sh
        06_main.sh
        07_main.sh
        08_main.sh

    03-post_processing/
        main_01.R
        main_02.R
        survival_analysis.ipynb

----------------------------------------------------------------------
Workflow Summary
----------------------------------------------------------------------

1. Pre-Processing (Shell + Python + Jupyter)
    - Download and validate dbGaP SRA files.
    - Extract FASTQ files using fasterq-dump with scratch storage and timeout handling.
    - Align reads with BWA-mem2 and generate sorted/indexed BAM files.
    - Perform basic QC and metadata preparation.

2. CNV Processing (GATK4 CNV)
    - CollectReadCounts for all samples.
    - Build Panel of Normals (CreateReadCountPanelOfNormals).
    - DenoiseReadCounts using the PoN.
    - Segment genomes using ModelSegments.
    - Export CNV segments and copy-ratio files.

3. Post-Processing (R + Jupyter)
    - Map CNV segments to gene coordinates.
    - Produce the final gene-by-sample CNV matrix.
    - Perform survival analysis (Kaplan–Meier, Cox) and create visualizations in Jupyter notebooks.

----------------------------------------------------------------------
Requirements
----------------------------------------------------------------------

Software:
    GATK 4.x
    BWA-mem2
    samtools
    SRA Toolkit
    Python 3.9+
    R 4.0+
    Slurm HPC environment

Key R Packages:
    data.table
    dplyr
    GenomicRanges
    readr

Key Python Packages:
    pandas
    numpy

----------------------------------------------------------------------
Usage Summary
----------------------------------------------------------------------

Pre-Processing:
    sbatch workflow/01-pre_processing/01_pre.sh
    sbatch workflow/01-pre_processing/02_pre.sh
    python workflow/01-pre_processing/03_pre.py
    jupyter notebook workflow/01-pre_processing/04_pre.ipynb

CNV Processing:
    sbatch workflow/02-processing/01_main.sh
    sbatch workflow/02-processing/02_main.sh
    sbatch workflow/02-processing/04_main.sh
    sbatch workflow/02-processing/05_main.sh
    sbatch workflow/02-processing/06_main.sh

Post-Processing:
    Rscript workflow/03-post_processing/main_01.R
    Rscript workflow/03-post_processing/main_02.R
    jupyter notebook workflow/03-post_processing/survival_analysis.ipynb

----------------------------------------------------------------------
Outputs
----------------------------------------------------------------------

- Copy-ratio files for each sample
- Denoised copy-ratio files
- CNV segmentation tables
- Gene-level CNV matrix
- Survival analysis results and figures

----------------------------------------------------------------------
Notes
----------------------------------------------------------------------

- All scripts comply with dbGaP privacy rules and do not require internet access after SRA retrieval.
- Scratch directories must be configured based on your HPC cluster.
- Interval lists must remain consistent across all samples.

----------------------------------------------------------------------
Contact
----------------------------------------------------------------------
For issues or contributions, please submit a GitHub issue or pull request.
